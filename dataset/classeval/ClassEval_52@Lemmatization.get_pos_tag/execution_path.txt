 --- modulename: execution_path, funcname: <module>
<string>(1):  --- modulename: execution_path, funcname: test
execution_path.py(50):             lemmatization = Lemmatization()
 --- modulename: execution_path, funcname: __init__
execution_path.py(18):         self.lemmatizer = WordNetLemmatizer()
execution_path.py(51):             result = lemmatization.get_pos_tag("The dog's barked at the mailman.")
 --- modulename: execution_path, funcname: get_pos_tag
execution_path.py(38):         pos_tags = []
execution_path.py(39):         sentence = self.remove_punctuation(sentence)
 --- modulename: execution_path, funcname: remove_punctuation
execution_path.py(47):         return sentence.translate(str.maketrans('', '', string.punctuation))
execution_path.py(40):         words = word_tokenize(sentence)
execution_path.py(41):         tagged_words = pos_tag(words)
execution_path.py(42):         for tagged_word in tagged_words:
execution_path.py(43):             pos_tags.append(tagged_word[1])
execution_path.py(42):         for tagged_word in tagged_words:
execution_path.py(43):             pos_tags.append(tagged_word[1])
execution_path.py(42):         for tagged_word in tagged_words:
execution_path.py(43):             pos_tags.append(tagged_word[1])
execution_path.py(42):         for tagged_word in tagged_words:
execution_path.py(43):             pos_tags.append(tagged_word[1])
execution_path.py(42):         for tagged_word in tagged_words:
execution_path.py(43):             pos_tags.append(tagged_word[1])
execution_path.py(42):         for tagged_word in tagged_words:
execution_path.py(43):             pos_tags.append(tagged_word[1])
execution_path.py(42):         for tagged_word in tagged_words:
execution_path.py(44):         return pos_tags
execution_path.py(52):             expected = ['DT', 'NNS', 'VBD', 'IN', 'DT', 'NN']
execution_path.py(53):             return result,expected
